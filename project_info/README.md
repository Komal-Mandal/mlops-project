# ğŸ“Œ MLOps Project Structure 

## ğŸ“– Project Overview

This project follows a professional MLOps folder structure used in real-world Machine Learning applications.

It helps in building, training, evaluating, and deploying ML models in an organized and scalable way.

The main goal of this structure is to keep code clean, reusable, and easy to debug.

## ğŸ“‚ Project Structure
```
project-root/
â”‚
â”œâ”€â”€ notebook/                     # Jupyter notebooks (EDA & experiments)
â”‚   â”œâ”€â”€ *.ipynb
â”‚
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ components/               # ML pipeline steps
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â””â”€â”€ model_pusher.py
â”‚   â”‚
â”‚   â”œâ”€â”€ configuration/            # Database & cloud connections
â”‚   â”‚   â”œâ”€â”€ mongo_db_connection.py
â”‚   â”‚   â””â”€â”€ aws_connection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud_storage/            # AWS S3 operations
â”‚   â”‚   â””â”€â”€ aws_storage.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_access/              # Data reading layer
â”‚   â”‚   â””â”€â”€ proj1_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ constants/                # Fixed values & paths
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ entity/                   # Data containers
â”‚   â”‚   â”œâ”€â”€ config_entity.py
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â”œâ”€â”€ metric_entity.py
â”‚   â”‚   â”œâ”€â”€ estimator.py
â”‚   â”‚   â””â”€â”€ s3_estimator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ exception/                # Custom error handling
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logger/                   # Logging setup
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipline/                  # Pipeline controller
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Helper functions
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚
â”œâ”€â”€ config/                       # YAML configuration files
â”‚   â”œâ”€â”€ model.yaml
â”‚   â””â”€â”€ schema.yaml
â”‚
â”œâ”€â”€ app.py                        # API entry point
â”œâ”€â”€ demo.py                       # Run training pipeline
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Docker setup
â”œâ”€â”€ .dockerignore                 # Docker ignore file
â”œâ”€â”€ setup.py                      # Package setup
â””â”€â”€ pyproject.toml                # Build configuration
```

### ğŸ”¹ src/

- This folder contains all the main source code of the project

### ğŸ”¹ src/components/

- Each file here represents one step of the ML pipeline.

- data_ingestion.py â†’ Fetches data from MongoDB / CSV

- data_validation.py â†’ Checks data quality and schema

- data_transformation.py â†’ Feature engineering and preprocessing

- model_trainer.py â†’ Trains the ML model

- model_evaluation.py â†’ Compares new and old models

- model_pusher.py â†’ Pushes best model to cloud (AWS S3)

### ğŸ”¹ src/pipline/

- Controls the flow of the entire project.

- training_pipeline.py â†’ Runs complete training process

- prediction_pipeline.py â†’ Handles prediction logic

### ğŸ”¹ src/entity/

- Contains data classes used to pass structured data between steps.

- config_entity.py â†’ Stores configuration values

- artifact_entity.py â†’ Stores output of each pipeline step

- estimator.py â†’ Model interface

- s3_estimator.py â†’ Model stored in AWS S3

- metric_entity.py -> Stores model performance results like accuracy, precision, recall, etc.
It helps decide how good the model is.

### ğŸ”¹ src/configuration/

- Handles external connections.

- mongo_db_connection.py â†’ MongoDB connection

- aws_connection.py â†’ AWS connection

### ğŸ”¹ src/cloud_storage/

- Used for cloud operations.

- aws_storage.py â†’ Upload/download files from AWS S3

### ğŸ”¹ src/data_access/

- Responsible for reading data from database or files.

- proj1_data.py â†’ Fetches data and converts it to DataFrame

### ğŸ”¹ src/constants/

- Stores fixed values like file paths and collection names.

### ğŸ”¹ src/utils/

- Contains helper functions used across the project.

- main_utils.py â†’ Read YAML, save/load models, etc.

### ğŸ”¹ src/logger/

- Manages logging for tracking execution and debugging.

### ğŸ”¹ src/exception/

Contains custom exception handling for clear error messages.

### âš™ï¸ Configuration Files (config/)

- model.yaml â†’ Model parameters and settings

- schema.yaml â†’ Dataset schema (columns and data types)

### ğŸ“„ Root Files Explanation

- app.py â†’ API entry point (FastAPI / Flask)

- demo.py â†’ Runs training pipeline

- requirements.txt â†’ Required Python libraries

- Dockerfile â†’ Docker configuration

- setup.py â†’ Makes project installable

- pyproject.toml â†’ Build and dependency management

### ğŸ“ notebook/ Folder (Very Important)

- The notebook folder contains all Jupyter Notebook (.ipynb) files.

### ğŸ“Œ Purpose of notebook/ folder

- This folder is mainly used for:

- Data exploration (EDA)

- Understanding the dataset

- Trying different models

- Feature engineering experiments

- ğŸ‘‰ These notebooks are for learning and experimentation, not for production.


